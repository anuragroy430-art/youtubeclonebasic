first npm init -y
we will push to git first 
git init 
git add .
git commit -m "initial commit"
git branch -M main
git remote add origin <your-repo-url> // get your repo url from github
git push -u origin main

after that u can just push your changes using
git add .
git commit -m "your message"
git push


second we will upload pics on this server only before cloudinary so if cloudinary connection fails we still have pics on our server
so we will create a folder named public in our root directory and inside that create another folder named temp inside that we will create .gitkeep file so that git will track this empty folder
then we will create .gitignore file in root directory and inside that we will write ( go to gitignore.io to generate .gitignore file for nodejs projects) // mrkandreev.name also works for generating .gitignore files

then we will create .env file in root directory 
what is .env file ?
it is a file where we will store our environment variables like database url , cloudinary api keys etc

then we will make a src folder in root directory 
inside src folder we will create app.js file
cd src 
touch app.js constants.js index.js

then we will create config folder inside src folder

js has two types of imports
1. commonjs
2. es6 modules
we will use es6 modules
so in package.json file we will add "type": "module", just below 
  "main": "index.js",

whenever we change anything in our code we have to restart the server again and again
to avoid that we will use nodemon
npm install --save-dev nodemon // --save-dev means it will be installed only in development environment not in production environment
then in package.json file inside scripts we will change test script to
"dev": "nodemon src/index.js" // now to start the server we will run npm run dev command

also es6 modules and .env has difficulty in working together , we have to use require to use dotenv in es6 modules

then cd src , mkdir controllers middlewares db models routes services utils
// controllers - to handle the logic 
// middlewares - to handle the middlewares like error handling , auth etc ( middlewares are functions that have access to request and response objects)
// db - to handle database connection ( mongoose connection or posgres connection )
// models - to handle database models ( mongoose models or sequelize models )
// routes - to handle routes ( express routes )
// services - to handle external services like cloudinary , nodemailer etc
// utils - to handle utility functions like generating jwt token , hashing password , file uploads , mailing  etc

install prettier for code formatting 
npm install --save-dev prettier
create .prettierrc file in root directory and add your preferred prettier configurations
create .prettierignore file in root directory to ignore files and folders from prettier formatting


now we will connect mongodb database using mongoose
go to mongodb atlas and create a free cluster
create a database named youtubeclone
give access to all ip addresses in network access ( in professional projects give access to only your server ip address for security reasons)
create a database user and password ( note them down )
then get your connection string from connect button in clusters dashboard click 
on compass and copy the connection string
replace <password> with your database user password


then in .env file add
MONGODB_URL=your-mongodb-connection-string
PORT=5000
then in constants.js file add
export const DB_NAME = "youtubeclone" // your database name

theres two ways to connect to mongodb using mongoose
1. using mongoose.connect() method directly in index.js file - pros : easy to implement , cons : clutters index.js file
2. creating a separate file in db folder named mongoose.js and exporting the connection function from there and importing it in index.js file
  pros : cleaner code , cons : slightly complex for beginners
we will use second method for better code structure

so we need packages like express , mongoose , dotenv  etc
npm install express mongoose dotenv 

the next importat thing is mongoose 
whenever we talk to mongodb error can occur due to network issues or database issues so wrap mongoose connection in try catch block to handle errors properly
or we can use promise .then().catch() method to handle errors
also db connection takes time so we have to make our function async and use await keyword before mongoose.connect() method
what is async await ?
async await is a way to handle asynchronous code in javascript
asynchronous code is code that runs in the background and does not block the main thread


in index.js file we will import mongoose  and DB_NAME from constants.js 
import mongoose from "mongoose";
import { DB_NAME } from "./constants.js";

then we will do a IIFE ( immediately invoked function expression) to connect to database
wrapped in try catch block to handle errors

then we import express and create an express app
and we listen to error events on mongoose connection to log any connection errors
app.on("error", (error) => {
  console.error("MongoDB connection error:", error);
}); // what does this do ? it listens to error events on mongoose connection and logs the error message

but this approach clutters index.js file so we will create a separate file in db folder named mongoose.js and export the connection function from there and import it in index.js file

then in index.js file we will import connectDB function from db/mongoose.js file and call it inside an IIFE to connect to database

another thing is we will use dotenv to load environment variables from .env file
we can use require to import dotenv but we are using es6 modules so we will use import statement , which is not supported by dotenv by default
so to use import statement we will do
import dotenv from "dotenv";
dotenv.config({
    path : ".env"
}); // this will load environment variables from .env file
then in package.json under "dev" script we will add
"dev": "nodemon -r dotenv/config --experimental-json-modules src/index.js"

after that if u get any errors read the errors 
one error can be importing problem of connectDB function from mongoose.js file
in the path of import always write last file name with extension like .js

next problem is constants.js file not found error 
make sure the path is correct ../constants.js  not ./constants.js as this will look inside src/db/constants.js
after this db is connected successfully message should appear in console

now lets try to fail the connection on purpose to see if error handling works
change the passowrd in MONGODB_URL in .env file to wrong password and run the server
you should see the error message in console
now change the password back to correct password and run the server again
now we should see db connected successfully message in console



now in app.js 
import express from "express";
const app = express();
export default app;
then in index.js as db connection was async it returns a promise so we will wait for db connection to be successful before starting the server
so after connectDB() call we will write .then and .catch to handle success and failure of db connection
before that we can also write app.on("error") method to listen to any mongoose connection errors and log them
then inside .then() method we will start the server using app.listen() method

then go to app.js file 
to make a express app , go to its documentation and see the api reference ( mostly 5x versions are used now )
we will be in either request or response cycle mostly 
inside request we have many properties like req.params , req.query , req.body , req.headers , req.cookies , req.baseurl etc
among these req.params , req.query and req.body are most used
req.params - to get url params like /user/:id
req.query - to get query params like /user?id=123
req.body - to get request body data like in post requests , data can be in json format or form data format

req.cookies - to get cookies from request headers
for cookies we need to install cookie-parser middleware
npm install cookie-parser

we will also install cors middleware to handle cross origin requests
npm install cors

then in app.js file
import cors from "cors";
import cookieParser from "cookie-parser";

we will use these middlewares using app.use() method 
app.use(cors( {} )); // inside cors we can pass options like origin , methods , credentials etc to configure cors as per our requirements
also set cors_origin in .env file to specify which origins are allowed to access our server

data can be sent in different formats like json , forms from body , url data , direct form etc
so we need to configure express
and its directly done by express itself

app.use(express.json({limit : '10mb'})); // to parse json data from request body
earlier we used body-parser package for this but now express has inbuilt body-parser

( we will use multer for form data parsing later when we implement file uploads )

cookie parser middleware helps acesss and set  cookies for user browser from my server


q) what is middleware in express ?
at first suppose a client hits a url suppose /instagram 
so this request goes to server (req,res cycle) so in the response we write 
something like res.send("welcome to instagram") 
request like this comes a lot of times to server and we want to process this request before sending response
thats where middleware comes in
middleware is a function that has access to request and response objects
it checks whether u r capable of accessing the resource or not
like authentication middleware checks whether u r logged in or not before accessing a resource
so middlewares are functions that run before the final request handler

another thing is we just dont have ( req , res ) in middlewares we also have (err, req , res , next)
this is error handling middleware
so whenever an error occurs in any middleware or route handler we can pass the error to next()
next is like a flag that tells express to go to the next middleware or route handler
so if we pass an error to next() it will go to the error handling middleware


next important thing is talking to database
we will talk a lot to database so insteading of writing database code in route handlers we will create separate files in services folder or utility class  to handle database operations
so create a file asynchandler.js in utils folder
this file will export a function that will take a async function as parameter and return a function that will handle errors using try catch block
this way we can avoid writing try catch block in every route

another thing we will do is standarize our api responses and error responses
so we will create a file apiError.js in utils folder
this file will export a class ApiError that will extend the built in Error class
this class will have a constructor that will take message and statusCode as parameters

we will also create a file apiResponse.js in utils folder
like we have built in error class in node , we dont have a built in response class
so we will create a class ApiResponse
that will standardize our api responses
this class will have a constructor that will take message , data and statusCode as parameters


another thing is we will check any error goes through our error handling apiError.js only 



ok now next stage is creating models - at first we will create user model and then video model  
so create user.model.js file in models folder
then create video.model.js file in models folder

managing watchhistory  will be quite complex , so we will learn about mongoose - aggregation pipelines and how to use them for complex queries
npm install mongoose-aggregate-paginate-v2 (for pagination of aggregation results)
what is aggregation pipeline ?
aggregation pipeline is a way to process data in mongodb
it is a series of stages that process data
each stage takes input from previous stage and produces output for next stage
stages are defined using an array of objects
each object represents a stage // learn more about it later

npm install mongoose-aggregate-paginate-v2
now import this package in video.model.js file and add pagination plugin to video schema
import mongooseAggregatePaginate from "mongoose-aggregate-paginate-v2";

mongoose allows a lot of methods , middlewares and plugins to work with schemas and models
like pre , post middlewares , statics methods , instance methods , plugins etc
we can add our own custom methods and middlewares to schemas and models
then in video.model.js file
videoSchema.plugin(mongooseAggregatePaginate); // this will add pagination methods to video model

next we will learn about bycrypt for hashing passwords
 bycrypt and bcryptjs 
 diff between hashing and encryption ?
 hashing is a one way function
 encryption is a two way function
 so we will use bcryptjs for hashing passwords
 npm install bcrypt

 we will also use jsonwebtoken for generating jwt tokens for authentication
 npm install jsonwebtoken
 what is jwt ? 
 jwt is a way to securely transmit information between parties as a json object
 jwt is used for authentication and authorization
 jwt consists of three parts
 1. header
 2. payload
 3. signature
 these three parts are separated by dots (.)
 header contains the type of token and signing algorithm
 payload contains the claims ( data )
 signature is used to verify the token and ensure that it has not been tampered with

now in user.model.js file
import bcrypt from "bcryptjs";
import jwt from "jsonwebtoken";
direct encryption is not possible 
so we will take help of mongoose hooks to hash password before saving to database
so we will use pre save hook to hash password before saving to database

after hashing the password we will create a method to compare password during login
as user will provide plain text password during login so we will create a method named isPasswordMatch to compare plain text password with hashed password in database
we have custom methods in mongoose models

now we come to jwt 
jwt is a bearer token , it means it should be sent in authorization header as Bearer token
acts as a key to access protected resources on server

now in .env file add
access_token_secret= your-secret-key // use a strong secret key for production
USE online jwt generator to generate a strong secret key
also add expiry time for access token
access_token_expiry=1d // 1d means 1 day , can be in hours , minutes etc  
we will also create refresh tokens
so refresh_token_secret= your-refresh-secret-key
refresh_token_expiry=7d // 7 days


then in user.model.js file
we will create a method named generateAuthTokens to generate access token and refresh token for user
we will use jwt.sign() method to generate tokens
we will pass user id as payload and secret key and expiry time from .env file 


next topic is file uploads using multer , 
fileupload is not done in our own server in production
we use cloudinary or aws s3 for file uploads
so we will use cloudinary for file uploads
npm install cloudinary
npm install multer

our strategy will be
we will upload files to cloudinary through multer only 
we will take files from client using multer middleware
and store it temporarily in our server public/temp folder
then we will upload these files to cloudinary using cloudinary sdk
then we will delete these files from our server to save space

we will create a file cloudinary.js in utils folder to handle cloudinary configuration and upload functions
then in cloudinary.js file
import { v2 as cloudinary } from "cloudinary";
 import fs from "fs"; // to read and delete files from server fs - file system module , part of nodejs
 fsPromises.unlink(filePath); // to delete file from server

cloudinary.config({
    cloud_name : process.env.CLOUDINARY_CLOUD_NAME,
    api_key : process.env.CLOUDINARY_API_KEY,
    api_secret : process.env.CLOUDINARY_API_SECRET
}); // configure cloudinary with credentials from .env file 

then we will create functions to upload images and videos to cloudinary
cloudinary.v2.uploader
.upload("dog.mp4", {
  resource_type: "video", 
  public_id: "my_dog",
  overwrite: true, 
  notification_url: "https://mysite.example.com/notify_endpoint"})
.then(result=>console.log(result)); // this is how to upload video to cloudinary
similarly for images we can use resource_type : "image"

// this above code is to upload directly from server
// but we will upload from local file path using multer

now we will create multer middleware to take files from client and store them temporarily 
why are we using middleware for file uploads ?
because we can inject this middleware in any route where we want to upload files
so create a file upload.middleware.js in middlewares folder
import multer from "multer";
read documentation of multer
for uploading we write 
const storage = multer.diskStorage({
    destination: function (req, file, cb) {
        cb(null, 'public/temp/')
    },
    filename: function (req, file, cb) {
        const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9)
        cb(null, uniqueSuffix + '-' + file.originalname)
    }
})

till now we have just done project setup


