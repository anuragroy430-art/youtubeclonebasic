first npm init -y
we will push to git first 
git init 
git add .
git commit -m "initial commit"
git branch -M main
git remote add origin <your-repo-url> // get your repo url from github
git push -u origin main

after that u can just push your changes using
git add .
git commit -m "your message"
git push


second we will upload pics on this server only before cloudinary so if cloudinary connection fails we still have pics on our server
so we will create a folder named public in our root directory and inside that create another folder named temp inside that we will create .gitkeep file so that git will track this empty folder
then we will create .gitignore file in root directory and inside that we will write ( go to gitignore.io to generate .gitignore file for nodejs projects) // mrkandreev.name also works for generating .gitignore files

then we will create .env file in root directory 
what is .env file ?
it is a file where we will store our environment variables like database url , cloudinary api keys etc

then we will make a src folder in root directory 
inside src folder we will create app.js file
cd src 
touch app.js constants.js index.js

then we will create config folder inside src folder

js has two types of imports
1. commonjs
2. es6 modules
we will use es6 modules
so in package.json file we will add "type": "module", just below 
  "main": "index.js",

whenever we change anything in our code we have to restart the server again and again
to avoid that we will use nodemon
npm install --save-dev nodemon // --save-dev means it will be installed only in development environment not in production environment
then in package.json file inside scripts we will change test script to
"dev": "nodemon src/index.js" // now to start the server we will run npm run dev command

also es6 modules and .env has difficulty in working together , we have to use require to use dotenv in es6 modules

then cd src , mkdir controllers middlewares db models routes services utils
// controllers - to handle the logic 
// middlewares - to handle the middlewares like error handling , auth etc ( middlewares are functions that have access to request and response objects)
// db - to handle database connection ( mongoose connection or posgres connection )
// models - to handle database models ( mongoose models or sequelize models )
// routes - to handle routes ( express routes )
// services - to handle external services like cloudinary , nodemailer etc
// utils - to handle utility functions like generating jwt token , hashing password , file uploads , mailing  etc

install prettier for code formatting 
npm install --save-dev prettier
create .prettierrc file in root directory and add your preferred prettier configurations
create .prettierignore file in root directory to ignore files and folders from prettier formatting


now we will connect mongodb database using mongoose
go to mongodb atlas and create a free cluster
create a database named youtubeclone
give access to all ip addresses in network access ( in professional projects give access to only your server ip address for security reasons)
create a database user and password ( note them down )
then get your connection string from connect button in clusters dashboard click 
on compass and copy the connection string
replace <password> with your database user password


then in .env file add
MONGODB_URL=your-mongodb-connection-string
PORT=5000
then in constants.js file add
export const DB_NAME = "youtubeclone" // your database name

theres two ways to connect to mongodb using mongoose
1. using mongoose.connect() method directly in index.js file - pros : easy to implement , cons : clutters index.js file
2. creating a separate file in db folder named mongoose.js and exporting the connection function from there and importing it in index.js file
  pros : cleaner code , cons : slightly complex for beginners
we will use second method for better code structure

so we need packages like express , mongoose , dotenv  etc
npm install express mongoose dotenv 

the next importat thing is mongoose 
whenever we talk to mongodb error can occur due to network issues or database issues so wrap mongoose connection in try catch block to handle errors properly
or we can use promise .then().catch() method to handle errors
also db connection takes time so we have to make our function async and use await keyword before mongoose.connect() method
what is async await ?
async await is a way to handle asynchronous code in javascript
asynchronous code is code that runs in the background and does not block the main thread


in index.js file we will import mongoose  and DB_NAME from constants.js 
import mongoose from "mongoose";
import { DB_NAME } from "./constants.js";

then we will do a IIFE ( immediately invoked function expression) to connect to database
wrapped in try catch block to handle errors

then we import express and create an express app
and we listen to error events on mongoose connection to log any connection errors
app.on("error", (error) => {
  console.error("MongoDB connection error:", error);
}); // what does this do ? it listens to error events on mongoose connection and logs the error message

but this approach clutters index.js file so we will create a separate file in db folder named mongoose.js and export the connection function from there and import it in index.js file

then in index.js file we will import connectDB function from db/mongoose.js file and call it inside an IIFE to connect to database

another thing is we will use dotenv to load environment variables from .env file
we can use require to import dotenv but we are using es6 modules so we will use import statement , which is not supported by dotenv by default
so to use import statement we will do
import dotenv from "dotenv";
dotenv.config({
    path : ".env"
}); // this will load environment variables from .env file
then in package.json under "dev" script we will add
"dev": "nodemon -r dotenv/config --experimental-json-modules src/index.js"

after that if u get any errors read the errors 
one error can be importing problem of connectDB function from mongoose.js file
in the path of import always write last file name with extension like .js

next problem is constants.js file not found error 
make sure the path is correct ../constants.js  not ./constants.js as this will look inside src/db/constants.js
after this db is connected successfully message should appear in console

now lets try to fail the connection on purpose to see if error handling works
change the passowrd in MONGODB_URL in .env file to wrong password and run the server
you should see the error message in console
now change the password back to correct password and run the server again
now we should see db connected successfully message in console



now in app.js 
import express from "express";
const app = express();
export default app;
then in index.js as db connection was async it returns a promise so we will wait for db connection to be successful before starting the server
so after connectDB() call we will write .then and .catch to handle success and failure of db connection
before that we can also write app.on("error") method to listen to any mongoose connection errors and log them
then inside .then() method we will start the server using app.listen() method

then go to app.js file 
to make a express app , go to its documentation and see the api reference ( mostly 5x versions are used now )
we will be in either request or response cycle mostly 
inside request we have many properties like req.params , req.query , req.body , req.headers , req.cookies , req.baseurl etc
among these req.params , req.query and req.body are most used
req.params - to get url params like /user/:id
req.query - to get query params like /user?id=123
req.body - to get request body data like in post requests , data can be in json format or form data format

req.cookies - to get cookies from request headers
for cookies we need to install cookie-parser middleware
npm install cookie-parser

we will also install cors middleware to handle cross origin requests
npm install cors

then in app.js file
import cors from "cors";
import cookieParser from "cookie-parser";

we will use these middlewares using app.use() method 
app.use(cors( {} )); // inside cors we can pass options like origin , methods , credentials etc to configure cors as per our requirements
also set cors_origin in .env file to specify which origins are allowed to access our server

data can be sent in different formats like json , forms from body , url data , direct form etc
so we need to configure express
and its directly done by express itself

app.use(express.json({limit : '10mb'})); // to parse json data from request body
earlier we used body-parser package for this but now express has inbuilt body-parser

( we will use multer for form data parsing later when we implement file uploads )

cookie parser middleware helps acesss and set  cookies for user browser from my server


q) what is middleware in express ?
at first suppose a client hits a url suppose /instagram 
so this request goes to server (req,res cycle) so in the response we write 
something like res.send("welcome to instagram") 
request like this comes a lot of times to server and we want to process this request before sending response
thats where middleware comes in
middleware is a function that has access to request and response objects
it checks whether u r capable of accessing the resource or not
like authentication middleware checks whether u r logged in or not before accessing a resource
so middlewares are functions that run before the final request handler

another thing is we just dont have ( req , res ) in middlewares we also have (err, req , res , next)
this is error handling middleware
so whenever an error occurs in any middleware or route handler we can pass the error to next()
next is like a flag that tells express to go to the next middleware or route handler
so if we pass an error to next() it will go to the error handling middleware


next important thing is talking to database
we will talk a lot to database so insteading of writing database code in route handlers we will create separate files in services folder or utility class  to handle database operations
so create a file asynchandler.js in utils folder
this file will export a function that will take a async function as parameter and return a function that will handle errors using try catch block
this way we can avoid writing try catch block in every route

another thing we will do is standarize our api responses and error responses
so we will create a file apiError.js in utils folder
this file will export a class ApiError that will extend the built in Error class
this class will have a constructor that will take message and statusCode as parameters

we will also create a file apiResponse.js in utils folder
like we have built in error class in node , we dont have a built in response class
so we will create a class ApiResponse
that will standardize our api responses
this class will have a constructor that will take message , data and statusCode as parameters


another thing is we will check any error goes through our error handling apiError.js only 



ok now next stage is creating models - at first we will create user model and then video model  
so create user.model.js file in models folder
then create video.model.js file in models folder

managing watchhistory  will be quite complex , so we will learn about mongoose - aggregation pipelines and how to use them for complex queries
npm install mongoose-aggregate-paginate-v2 (for pagination of aggregation results)
what is aggregation pipeline ?
aggregation pipeline is a way to process data in mongodb
it is a series of stages that process data
each stage takes input from previous stage and produces output for next stage
stages are defined using an array of objects
each object represents a stage // learn more about it later

npm install mongoose-aggregate-paginate-v2
now import this package in video.model.js file and add pagination plugin to video schema
import mongooseAggregatePaginate from "mongoose-aggregate-paginate-v2";

mongoose allows a lot of methods , middlewares and plugins to work with schemas and models
like pre , post middlewares , statics methods , instance methods , plugins etc
we can add our own custom methods and middlewares to schemas and models
then in video.model.js file
videoSchema.plugin(mongooseAggregatePaginate); // this will add pagination methods to video model

next we will learn about bycrypt for hashing passwords
 bycrypt and bcryptjs 
 diff between hashing and encryption ?
 hashing is a one way function
 encryption is a two way function
 so we will use bcryptjs for hashing passwords
 npm install bcrypt

 we will also use jsonwebtoken for generating jwt tokens for authentication
 npm install jsonwebtoken
 what is jwt ? 
 jwt is a way to securely transmit information between parties as a json object
 jwt is used for authentication and authorization
 jwt consists of three parts
 1. header
 2. payload
 3. signature
 these three parts are separated by dots (.)
 header contains the type of token and signing algorithm
 payload contains the claims ( data )
 signature is used to verify the token and ensure that it has not been tampered with

now in user.model.js file
import bcrypt from "bcryptjs";
import jwt from "jsonwebtoken";
direct encryption is not possible 
so we will take help of mongoose hooks to hash password before saving to database
so we will use pre save hook to hash password before saving to database

after hashing the password we will create a method to compare password during login
as user will provide plain text password during login so we will create a method named isPasswordMatch to compare plain text password with hashed password in database
we have custom methods in mongoose models

now we come to jwt 
jwt is a bearer token , it means it should be sent in authorization header as Bearer token
acts as a key to access protected resources on server

now in .env file add
access_token_secret= your-secret-key // use a strong secret key for production
USE online jwt generator to generate a strong secret key
also add expiry time for access token
access_token_expiry=1d // 1d means 1 day , can be in hours , minutes etc  
we will also create refresh tokens
so refresh_token_secret= your-refresh-secret-key
refresh_token_expiry=7d // 7 days


then in user.model.js file
we will create a method named generateAuthTokens to generate access token and refresh token for user
we will use jwt.sign() method to generate tokens
we will pass user id as payload and secret key and expiry time from .env file 


next topic is file uploads using multer , 
fileupload is not done in our own server in production
we use cloudinary or aws s3 for file uploads
so we will use cloudinary for file uploads
npm install cloudinary
npm install multer

our strategy will be
we will upload files to cloudinary through multer only 
we will take files from client using multer middleware
and store it temporarily in our server public/temp folder
then we will upload these files to cloudinary using cloudinary sdk
then we will delete these files from our server to save space

we will create a file cloudinary.js in utils folder to handle cloudinary configuration and upload functions
then in cloudinary.js file
import { v2 as cloudinary } from "cloudinary";
 import fs from "fs"; // to read and delete files from server fs - file system module , part of nodejs
 fsPromises.unlink(filePath); // to delete file from server

cloudinary.config({
    cloud_name : process.env.CLOUDINARY_CLOUD_NAME,
    api_key : process.env.CLOUDINARY_API_KEY,
    api_secret : process.env.CLOUDINARY_API_SECRET
}); // configure cloudinary with credentials from .env file 

then we will create functions to upload images and videos to cloudinary
cloudinary.v2.uploader
.upload("dog.mp4", {
  resource_type: "video", 
  public_id: "my_dog",
  overwrite: true, 
  notification_url: "https://mysite.example.com/notify_endpoint"})
.then(result=>console.log(result)); // this is how to upload video to cloudinary
similarly for images we can use resource_type : "image"

// this above code is to upload directly from server
// but we will upload from local file path using multer

now we will create multer middleware to take files from client and store them temporarily 
why are we using middleware for file uploads ?
because we can inject this middleware in any route where we want to upload files
so create a file upload.middleware.js in middlewares folder
import multer from "multer";
read documentation of multer
for uploading we write 
const storage = multer.diskStorage({
    destination: function (req, file, cb) {
        cb(null, 'public/temp/')
    },
    filename: function (req, file, cb) {
        const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9)
        cb(null, uniqueSuffix + '-' + file.originalname)
    }
})

till now we have just done project setup

now we will learn about http crash course 

When you build backend controllers (in Node, Java, Spring Boot, Django, etc.), you‚Äôre essentially writing code that:
Receives HTTP requests
Processes them
Returns HTTP responses
So if you don‚Äôt understand HTTP clearly, controllers will feel like a ‚Äúblack box‚Äù.
hyper text transfer protocol (http)

it is a protocol used for communication between client and server
http vs https 
http is not secure , https is secure
https uses ssl/tls to encrypt data between client and server
http sends data in plain text

what are http headers ?
these are meta data - key value pairs sent in request and response
like content-type , authorization , cookies , user-agent etc
what do these headers do ?
few examples are used in caching , authentication , session cookies , (manage state-guest , logged in )etc
categories of headers
1. request headers - sent by client to server
2. response headers - sent by server to client
3. representation headers - tells data is in which encoding format like json , xml , html etc , which compression format like gzip , deflate etc
4.payload headers - tells size of data being sent in request or response
5. security headers - used to secure data like csp , hsts , x-frame-options etc

most common headers
1. accept - tells server which content types client can handle - application/json , text/html etc
2. user-agent - tells server about client device and browser , from which application the request is sent , which browser engine is used etc
3. authorization - used for authentication , contains credentials like bearer token , basic auth etc
4. content-type - tells server about type of data being sent in request body - application/json , multipart/form-data etc
5. cookie - contains cookies sent by client to server , used for session management
6. cache -control - used to control caching of data , like no-cache , no-store , max-age etc

production grade headers  
cors headers
1.acess-control-allow-origin
2.acess-control-allow-methods 
3.acess-control-allow-credentials
security headers

headers do not automatically do anything , they are like meta data - like if this is allowed by server then do this , we have to implement the logic in server to handle these headers

http methods - basic set of operations that can be performed on a resource
1. GET - to fetch data from server
2. POST - to create new resource on server (add new data)
3. PUT - to update existing resource on server (replaces entire resource)
4. DELETE - to delete resource from server
5. PATCH - to partially update existing resource on server (only updates specified fields)
6. OPTIONS - to get supported http methods for a resource
7. HEAD - to get only headers of a resource without body
8. TRACE - to trace the path of a request to a resource

http status codes - three digit codes sent in response to indicate status of request
1xx - informational 
2xx - success (like 200 ok , 201 created etc)
3xx - redirection (like 301 moved permanently , 302 found etc)
4xx - client error (like 404 not found , 401 unauthorized etc)
5xx - server error ( like 500 internal server error , 503 service unavailable etc)
most common status codes

100-continue,102-processing,200-ok,201-created,202-accepted,204-no-content,301-moved-permanently,302-found,304-not-modified,400-bad-request,401-unauthorized,403-forbidden,404-not-found,409-conflict,500-internal-server-error,502-bad-gateway,503-service-unavailable

NOW JUST LOGIC , ALL SETUP DONE

now we will register a user , how to write controller for that ?
create a file user.controller.js in controllers folder
import {asyncHandler} from "../utils/asyncHandler.js";
const registerUser = asyncHandler(async (req, res) => {
   // get user data from req.body
   // validate user data
   // check if user already exists
   // hash password
   // create user in database
   // generate auth tokens
   // send response with user data and tokens
}); but for now we will just send a response with message user registered successfully
res.status(201).json({
    message : "User registered successfully"
});

next step is routes 
what is route ?
route is a path that maps to a controller function
it means when a client hits a url like /api/users/register with a http method like POST
then this request is handled by a controller function like registerUser

so create a file user.routes.js in routes folder



we have exported so many things from different files
now where will we import all these things and use them ?
we will do in app.js file , generally middlewares and routes are imported and used in app.js file

so in app.js file

// wherever our app is running (url) suppose local host we will just call the method of register user but no we dont do this 
//routes declaration
earlier we were writing app.get and it was working bcz routes controllers were in app.js file itself
// now we have separated routes and controllers in different files so we will use app.use() method
import userRoutes from "./routes/user.routes.js";
app.use('/users', userRoutes); // this means all routes in userRoutes will be prefixed with /users
so whenever client hits /users url it will go to userRoutes file 
from there it will go to respective controller functions

so in routes files we will write
const router = Router();
router.route("/register").post( registerUser ); // POST request to /users/register will be handled by registerUser controller
export default router; 

even if we write a login route in user.routes.js file
router.route("/login").post( loginUser ); // POST request to /users/login will be handled by loginUser controller
no need to write app.use() again in app.js file as we have already prefixed /users to all routes in userRoutes

another good practise is instead of /users we write /api/v1/users
this way we can version our api and in future if we want to make breaking changes we can
create a new version of api like /api/v2/users and keep both versions running simultaneously

ONE ERROR ISSUE CAN COME 
import and export issues
if we export default then we have to import without curly braces {}
if we export named export then we have to import with curly braces {}


ok so now how will we test our register user controller ?
we can use thunder client extension in vscode or postman application
postman is industry standard for api testing
(download and install postman application from postman website)
postman does what ? - it allows us to send http requests to our server and get responses
write a post request to http://localhost:8000/api/v1/users/register
now in collection if we write this and click send we will get error
CANNOT GET error, why ?
bcz we are using get here but our route is post
so change it to post and click send
now we should get response with message user registered successfully

now instead of just sending message we will implement the logic to register user properly
SO LOGIC BUILDING STARTS FROM HERE
we will breakdown the logic into steps
1. get user details from frontend 
2. validation of user details (email format , password strength etc , isempty fields etc)
3.check if user already exists in database (by email and username)
4.check file uploads (profile pic etc) that is avatar and cover image in our model
5.upload images to cloudinary using cloudinary sdk (check for avatar cz that is required field)
6.create user object ( nosql database )  and create entry in database(db calls)
7.remove passowrd and refresh token from response
8.check if user is created successfully (if not send error response)

1. get user details from frontend
destructure user details from req.body
const { username , email , password , fullname } = req.body;
now check postman for testing by doing console.log
write the local host url in postman and in body select raw and json format
then send data like 
{
    "username" : "john_doe",
    "email" : "john@example.com",}
now we will see the console log in terminal

now we have handeled only data from req.body
next we will handle file uploads using multer middleware cz we cant handle file uploads using req.body
so in user.routes.js file
import { upload } from "../middlewares/upload.middleware.js";
now how to use this upload middleware ? 
we will use it in route handler
we see in /register route if anyone hits - registerUser method is called
so before calling registerUser method we will call upload middleware
so we will write upload.single('avatar') for single file upload
but we have two files to upload avatar and coverImage
so we will use upload.fields() method for multiple file uploads
upload.fields takes an array of objects as parameter

so now we can take files 

2. validation of user details (email format , password strength etc , isempty fields etc)
we can use joi or yup for validation but now we will do simple validation using if else statements

so import ApiError from "../utils/apiError.js";
and check if ( fullname && email && username && password ) {    
  throw new ApiError("All fields are required", 400); // 400 bad request
}

3.check if user already exists in database (by email and username)

in user.model.js , we also have exported the user model , this export can directly talk to database
so we will import User model in user.controller.js file
import {User} from "../models/user.model.js"; {} bcz we have used named export in user.model.js file
then we will check if user already exists in database by email and username

User.findOne({ $or : [{username} , {email}]}) // this will check if user with given username or email already exists in database
.findone() method - finds the first user that matches the query
User.findOne({ $or : [{username} , {email}]})
$or is a mongo operator that checks if any of the conditions are true ($and , $not etc are other operators)

4.check file uploads (profile pic etc) that is avatar and cover image in our model

just like there is req.body for data there is req.files for files uploaded using multer middleware 
middleware adds a files property to req object 
req.files?. we are using optional chaining operator ?. to avoid error if files property is undefined
req.files?.avatar[0].path - this will give the path of uploaded avatar file ,, [0]  is the first property and theres a path property in that object

now check if avatar file is uploaded as it is required field in our model

5.upload images to cloudinary using cloudinary sdk (check for avatar cz that is required field)

we have already created cloudinary.js file in utils folder to handle cloudinary configuration and upload functions
so we will import {uploadToCloudinary} from "../utils/cloudinary.js";
then we will upload avatar and coverImage to cloudinary using uploadToCloudinary function

6. create user object ( nosql database )  and create entry in database(db calls)

user.create() method to create user in database
//diff between .url and .secure_url
url - http url
secure_url - https url 

7. remove passowrd and refresh token from response

const createdUser = await User.findById(user._id).select("-password -refreshToken");
this will remove password and refreshToken from response
.select() method is used to select specific fields from the document
also this was used to check if user is created successfully or not 

8.check if user is created successfully (if not send error response)
if(!createdUser) {
    throw new ApiError("User registration failed", 500); // 500 internal server error
}

9. if no errors send success response
we already have a structure for api responses in apiResponse.js file
so we will import ApiResponse from "../utils/apiResponse.js";
then send response using ApiResponse class




first lets check our register user api in postman
use post method 
http://localhost:8000/api/v1/users/register
then in body select form-data
then add fields like
key - username , value - john_doe
key - email , value - etc 
we are not using raw json format cz we have file uploads also

some errors are coming like validation failed  bcz we used fullname instead of fullName

check cloudinary and mongo atlab for uploaded images and created user document
mongo atlas stores data in bson format not json format 
bson vs json ?
bson is binary json format
bson supports more data types than json like date , binary data etc

now we want to unlink files from server after uploading to cloudinary to save space
so in cloudinary.js file after uploading to cloudinary we will delete the file from server using
using fs.unlinksync(filePath); // this will delete the file from server
basically it means after uploading to cloudinary we dont need the file in our server so we will delete it to save space


we also check what happens if cover image is not uploaded as it is optional field
some error is happening like cannot read property path of undefined
we have already used optional chaining operator ?. but still error is coming
bcz after that we are not immediately checking if coverImage file is present or not like we did for avatar file
so we will just use if condition to check if coverImage file is present or not
let coverImage ;
if (req.files && Array.isArray(req.files.coverImage) && req.files.coverImage.length > 0) 



now lets study about what what data are sent 
if we do console.log(req.files) we will get 

  avatar: [
    {
      fieldname: 'avatar',
      originalname: 'profile.jpg',
      encoding: '7bit',
      mimetype: 'image/jpeg',
      destination: 'public/temp/',
      filename: '1688123456789-123456789-profile.jpg',
      path: 'public/temp/1688123456789-123456789-profile.jpg',
      size: 12345
    }
  ], and same for cover image 


  postman
NOW WE WILL LEARN POSTMAN
we can create collections in postman to organize our apis
inside collection we can create folders to organize apis further
and inside folders we can create requests 
next important thing is environment variables in postman
we can create environment variables in postman to store values like base url , auth tokens , user ids etc
so create a new environment named local
then add a new variable named base_url with value http://localhost:8000/api/v1
then we share this environment from no environment to our collection named meowtube
 then in requests instead of writing full url we will write {{server}}/users/register 



 WHATS THE DIFF BETWEEN ACCESS TOKEN AND REFRESH TOKEN ?
Access Token:
- Short-lived token (typically expires in minutes to hours).\
whenever we need to access protected resources which requires authentication we can do that if we have a valid access token.
- eg only logged in users can upload videos , comment on videos , like videos etc but accesstoken can expire quickly for security reasons suppose 30mins ,so after 30mins user has to login again to get new access token , this is where refresh token comes in picture

refresh Token:
- Long-lived token (can last days, weeks, or even months). 
- refresh tokens are there in our database associated with user
- we validate user through access token only but everytime you dont have to login again and again to get new access token
if u have refresh token , hit a endpoint /refresh-token with refresh token in body or headers 
- now if refresh token is valid(match with db) and not expired we will generate a new access token for user and send it in response
- this way user can stay logged in for longer period without re-entering credentials frequently


so using these two tokens 
we will implement login user controller next
algo for login user controller
1. get email or username and password from req.body
2. validate email/username and password (isempty fields etc)
3. find user in database by email or username
4. if user not found send error response
5. compare password using isPasswordMatch method in user model
6. if password does not match send error response
7. generate auth tokens(access and refresh) using generateAuthTokens method in user model
8. send cookie and then response with user data and tokens

1.
const {email ,  username , password} = req.body;
then check if username or email is provided along with password
then check 
3. find user in database by email or username
 if it was just email login we would write 
 user.findOne ({email}) 
but as we have both email and username login so we will use $or operator (mongo operator )
  const user = await User.findOne({ $or: [{ email }, { username }] });
if we cant find user send error response

5. compare passowrd using ispasswordmatch method in user model
we have already created isPasswordMatch method in user model
so we will use it here
const isMatch = await user.isPasswordMatch(password); we will use user not User cz we have already fetched user from database 
User is a mongoose model , user is our fetched user document from database
if password does not match send error response

7. generate auth tokens(access and refresh) 

so we will create a seperate function to generate auth tokens
there only create a method named generateAuthTokens

const generateAuthTokens = async (userId) =>
{ try{
        await User.findById(userId);
        const accessToken = user.generateAccessToken();
        const refreshToken = user.generateRefreshToken();
    }catch(error){
        throw new apiError(500,"Error generating auth tokens");
    }
}
but we will also store refresh token in database with user
user.refreshToken = refreshToken;

 await user.save({validateBeforeSave : false}); // disable validation before saving , because we are only updating refresh token
//when we will save , mongoose will try to validate all fields , but we are only updating refresh token , so other fields may be invalid , so we disable validation before saving

now we have a method to generate auth tokens
so in login controller we will call this method to generate auth tokens

const {accessToken , refreshToken} = await generateAuthTokens(user._id);

9. send cookie and then response with user data and tokens
we will send access token in response body and refresh token in  cookie

what is a cookie ?
a small piece of data stored on client side (browser) by server
used for session management , authentication , personalization etc

we have to define cookie options
const cookieOptions = {
    httpOnly : true, // cookie cannot be accessed by client side scripts
    secure : true , // cookie will be sent only over https
    sameSite : "strict", // cookie will be sent only to same site
    maxAge : 7 * 24 * 60 * 60 * 1000 // cookie will expire in 7 days
};
by default cookie can be modified by client side scripts like javascript (frontend)
so to prevent this we set httpOnly to true so only server can access the cookie
then we will set cookie in response using res.cookie() method
res.cookie("refreshToken" , refreshToken , cookieOptions); // set refresh token in cookie
then we will send response using ApiResponse class
res.status(200).json(new apiResponse

NOW USER IS LOGGED IN SUCCESSFULLY
NOW WE WILL WRITE LOGOUT USER CONTROLLER AND THEN SET ROUTES 

how to logout a user ? 
1.claer cookies from client side
1. clear refresh token from database
so in 
User.findbyid () but how will we get user id here ?

earlier in login we were finding user by email or username from req.body
but now if we find user by email or username from req.body it means anyone can logout any user by just knowing their email or username
SOLUTION
middleware to authenticate user using access token
we will create our own authentication middleware to authenticate user using access token
eg we created cookie parser middleware
so we could use req.cookies to get cookies from request
res.cookie to set cookies in response

similarly we will create auth.middleware.js file in middlewares folder
we will create a verifyToken function to verify access token from authorization header
what is a true login session ?
when user logs in successfully and gets access token and refresh token
so we will verify based on access token

//req.cookies to get cookies from browser
//we use ? optional chaining to avoid errors if cookies is undefined
//If accessToken is not found in cookies, we check the Authorization header
//authorization header is used in mobile apps or external clients where cookies might not be available
// in postman we can set authorization header manually
//The typical format of the Authorization header is "Bearer <token>" 
// so we split the string by space and take the second part as the token
then check if access token is present or not
if not present send error response

then if we have access token we will verify it using jwt.verify() method and ask what what information we have stored in token while generating it
(go to usermodel file and check generateAccessToken method , how much data we have stored in token while generating it )
so we have to decode token to get user id from it
so we will first
import jwt from "jsonwebtoken";
then we will verify token using
const decoded = jwt.verify(token, process.env.ACCESS_TOKEN_SECRET);
token will be decoded only if u have the secret key used to sign the token
next we will get user id from decoded token but without some fields like password and refresh token
const user = await User.findById(decoded.id).select("-password -refreshToken");
if user not found send error response
if user found we will attach user to req object
req.user = user; // now in any route handler we can access logged in user using req.user
then call next() to pass control to next middleware or route handler
next();
now how will we use this middleware ?

we will use this middleware in routes
we will just call loginUser controller without auth middleware cz user is not logged in yet
and we will use auth middleware in logout route cz user has to be logged in to logout
router.route("/logout").post(verifyJWT ,  logoutUser);
so verifyJWT middleware will run first to verify access token
if token is valid it will call logoutUser controller
thats why next() is called in verifyJWT middleware to pass control to next middleware or route handler
like this we can call as many middlewares as we want in routes

now in logoutUser controller
we will get user id from req.user object 
how ? what is req.user ?
we have attached user to req object in verifyJWT middleware
so we can access logged in user using req.user
we will use findbyidAndUpdate method to clear refresh token from database
if we used findbyid() method we would have to call save() method to save changes to database
but findbyidAndUpdate method updates the document directly in database
we will then use mongo operator $set to set refreshToken to null
new : true // this will return the updated document not the old one in response
now we will clear cookie from client side 
so we will need to set cookie options again
const cookieOptions = {
    httpOnly : true, // cookie cannot be accessed by client side scripts
    secure : true , // cookie will be sent
}
then we will clear cookie using res.clearCookie() method
and then send response using ApiResponse class

sidenote : sometimes we write ( req , _ , next ) when we dont need res object in middleware  

now lets do testing of login and logout user apis in postman
create a new request in postman for login user
and another request for logout user
and in body select raw and json format
then send data like 
{
    "username" : "john_doe",
    "password" : "Password@123"}
then click send
we should get response with user data and access token

TOPIC : ACCESS AND REFRESH TOKEN
the main purpose of using access tokens and refresh tokens is - so that user dont have to give email and password again and again to access

‚úÖ Step 1: User Logs In

User sends email/password to server.

Server validates and returns:

Access Token (expires soon)

Refresh Token (long valid)

üì• Step 2: User Calls APIs

App sends access token in headers (e.g., Authorization: Bearer <token>).

Server checks token ‚Üí if valid, returns data.

‚õî Step 3: Access Token Expires

App tries API ‚Üí server says ‚Äútoken expired‚Äù.

üîÅ Step 4: Refresh Token Used

App sends refresh token to a special API endpoint like /refresh-token.

Server verifies refresh token.

If valid ‚Üí server returns a new access token.

üöÄ Step 5: Continue Using App

User does not need to log in again.

why is this better than just using access token ?
1. Security - access tokens are short lived so even if they are compromised the damage is limited (If we used only 1 token with long validity, and if someone stole it, they could use your account for a long time.)

to do this we will -
we will create a new controller named refreshTokenUser in user.controller.js file
then we will create a new route for this controller in user.routes.js file
check refreshAuthToken method in user.controller.js file
1. get refresh token from req.cookies
2. validate refresh token (isempty etc)
3. verify refresh token using jwt.verify() method
4. find user in database by id from decoded token
5. if user not found or refresh token does not match send error response
6. generate new access token using generateAccessToken method in user model
7. send response with new access token

now in the route file user.routes.js
router.route("/refresh-token").post( refreshAuthToken ); // POST request to /users/refresh-token will be handled by refreshAuthToken controller
it is a secured route cz user is logged in and has refresh token in cookies


lets manipulate user model more , we will create more controllers
like change password , get user profile , update user profile etc
another controller is changeFileUploads (updateUserAvatarCoverImage) 
always manipulate files using a seperate controller
why ? bcz file uploads are complex and have many edge cases
so create a new controller named updateUserAvatarCoverImage in user.controller.js file








NOW WE WILL WRITE SUBSCRITION MODEL 
subscription model has a channel and its subscribers
now channel is a user too and subscribers are also users
so we will create a reference to user model in subscription model

 so create a file subscription.model.js in models folder
 and write it 
 complexities we will face :
 1. channel has how many subscribers
 2. subscribed( not subscribed ) button if logged in 
 3. showing profiles of subscribers of a channel

 THEORYYYYYYY
 UNDERSTANDING THE SUBSCRIPTION SCHEMA 

 why did we create a separate Subscription schema instead of embedding subscribers directly within the User schema?
1. Scalability: A user can have a large number of subscribers. Embedding all subscribers within the User document can lead to very large documents, which can be inefficient to read and write. A separate Subscription schema allows for better scalability as the number of subscribers grows.
in simple words we would store all the userids of subscribers in an array in user model
but if a user has millions of subscribers then the user document will become very large and inefficient to read and write (DSA)
2. Query Flexibility: With a separate Subscription schema, we can easily query subscriptions independently of users. For example, we can quickly find all subscribers of a particular channel or all channels a user is subscribed to without loading the entire User document.

SEE SUBSCRIPTION MODEL PIC FOR REFF , 
our subscription model has two fields
1. channel -  (the channel being subscribed to)
2. subscribers -  (users who have subscribed to the channel)
suppose we have channels - yestheory , freecodecamp , travelvlogs and users - a , b , c , d , e
 now if user a subscribed to yestheory 
 a document will be created in subscription collection like
 {
    channel : yestheory_id,
    subscribers : a
 }
 then if user b also subscribed to yestheory
 {
    channel : yestheory_id,
    subscribers :  b
 }
 then if user c subscribed to freecodecamp
 {
    channel : freecodecamp_id,
    subscribers : c
 }
  then if user a also subscribed to freecodecamp
  {
      channel : freecodecamp_id,
      subscribers : a
  }
  so this way we can have multiple documents for same channel with different subscribers
  now if we want to find how many subscribers yestheory (a channel) has
  we will count documents with channel = yestheory_id

  now if we want to find which channels user a has subscribed to
  we will find documents with subscribers = a


MONGODB AGGREGATION pipeline
WHAT IS AGGREGATION ?
Aggregation is a way of processing data in MongoDB to perform complex operations like filtering, grouping, sorting, and transforming data.
it is similar to sql group by clause
Aggregation is done using aggregation pipeline which is a series of stages that process data step by step.
each stage takes input from previous stage and produces output for next stage
eg : suppose we have 100 documents in a collection and due to some condition we want to filter only 10 documents
so first stage will filter 10 documents from 100 documents
then second stage will group these 10 documents based on some field
then third stage will sort these grouped documents based on some field
then fourth stage will project only required fields from these sorted documents
finally we will get the desired output

we can write aggregation inside of mongodb atlas using aggregation tab
[
  {}, stage 1
  {}, stage 2
  {}, stage 3
]
to join two collections we use $lookup stage in aggregation pipeline
$lookup stage performs left outer join to a collection in the same database to filter in documents from the "joined" collection for processing.

LEARN ABOUT MONGODB , SEE OTHER folder

NOW LETS WRITE SUBSCRIPTION CONTROLLERS
we will create two controllers


getUserChannelProfile - to get channel profile along with subscription status and subscriber count

whenever we go to a channel , we visits it url like /channel/:channelId
so we will get username from req.params
then we will find channel user in database by username

next we can do user.find({username}) but this will search the db for the user , u will take it  and then based on its id will run aggregation
so this is a long approach
so we will use aggregation pipeline with $match stage to find channel user by username and then $lookup stage to join subscription collection to get subscription status and subscriber count
therefore user.aggregate([ {},{},{} ]) 

so first stage is $match stage to find channel user by username
{ $match : { username : username } } // username from req.params

after this we are getting channel user document ( a single document as username is unique )

now we will use $lookup stage to join subscription collection to get subscription status and subscriber count

next to see which which channel user is subscribed to
we will use $lookup stage again to join subscription collection to see if logged in user is subscribed

next we will use addfields stage to add two new fields
to count subscribers we will use $size operator to count number of documents in subscriptions array and same for subscribedToChannel array

next we will see whether logged in user is subscribed to this channel or not

                isSubscribed : {
                    $cond : {
                        if : {
                            $in : [ req.user?._id , "$subscribers.subscriber" ] // check if logged in user id is in subscribers array  and subscriber object 
                        },
                        then : true,   
                        else : false
                    }       
            }
//this will check if logged in user id is in subscribers array of subscription collection for this channel 

lastly we will project only required fields using $project stage
$project stage is used to include or exclude fields from the output documents
if we set a field to 1 it means include that field in output
if we set a field to 0 it means exclude that field from output

now what data structure does aggregate method return ?
it returns an array of documents
so to get single document we will use [0] to get first document from array
why first document ?
bcz username is unique so only one document will be returned in array


NEXT WE WRITE ABOUT WATCH HISTORY CONTROLLERS

watchhistory is a array where all the ids of watched videos are stored , so we will get a lot of documents 
we will do $lookup from watch history collection to video collection to get video details
but we also need owner details of video
so we will do another $lookup from user collection to get owner details of video
so we will do nested lookups

SIDENOTE : req.user?._id gives us a string not an object id
mongoose automatically converts string to object id when querying the database

so for match stage 
{ $match : { user : mongoose.Types.ObjectId(req.user?._id) } } // convert string to object id using mongoose.Types.ObjectId() method

u have seen while lookup we used subscriptions / videos / users instead of Subscription / Video / User as these are the collection names in mongodb atlas ( it makes first letter small and adds s at the end for plural form)



 



















  




